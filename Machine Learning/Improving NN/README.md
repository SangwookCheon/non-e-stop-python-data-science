# Improving Neural Networks - Overview
Machine learning involves building the model to fit to the data. However, much of machine learning is about having the skills to improve the model. It is highly unlikely that an initial model will work like magic; a programmer needs to be able to analyze the model to detect overfitting (fitting too much to training data, therefore not able to generalize to external data), underfitting (the opposite of overfitting), and other problems. Other than figuring out problems, hyperparamaters can be tuned to make the model even better. As there are so many parameters to play around with, it is essential to know some systematic techniques for working with these. I learned a lot of optimization techniques from experts out there. It is quite hard to fully digest all these concepts, so I put the learning resources here to review them from time to time. 

## Coursera Deeplearning.ai Specialization 
[Linke to the course](https://www.coursera.org/specializations/deep-learning)   
Course: | Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization
* **Gradient+Checking+v1-Copy1.ipynb** - 
* **Initialization.ipynb** - 
* **Optimization+methods.ipynb** - 
* **Regularization+-+v2.ipynb** - 
* **Tensorflow+Tutorial.ipynb** - I do not usually use pure Tensorflow when making models, because it is pretty low-level, meaning it is challenging to learn and implement. Instead of this, I use Keras library to quickly and effectively build models. I created a separate folder for Keras, so please refer to that. 
